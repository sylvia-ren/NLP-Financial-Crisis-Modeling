{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes trouvÃ©es : 370399\n",
      "Calcul du sentiment Loughran-McDonald (Finance Specific)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 370399/370399 [00:18<00:00, 19546.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier daily_sentiment_lm_final.csv gÃ©nÃ©rÃ© !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pysentiment2 as ps  # <--- Nouvelle librairie\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Configuration\n",
    "FILE_PATH = '../data/headlines.csv'\n",
    "START_DATE = '2005-01-01'  \n",
    "END_DATE = '2008-12-31'\n",
    "\n",
    "# 2. Chargement & Nettoyage (Ton code existant)\n",
    "df_large = pd.read_csv(FILE_PATH)\n",
    "\n",
    "col_text = [c for c in df_large.columns if 'title' in c.lower() or 'headline' in c.lower()][0]\n",
    "col_date = [c for c in df_large.columns if 'date' in c.lower() or 'published' in c.lower()][0]\n",
    "\n",
    "# Conversion date\n",
    "df_large[col_date] = pd.to_datetime(df_large[col_date].astype(str), format='%Y%m%d', errors='coerce')\n",
    "df_large = df_large.dropna(subset=[col_date])\n",
    "\n",
    "# Filtre temporel\n",
    "mask = (df_large[col_date] >= START_DATE) & (df_large[col_date] <= END_DATE)\n",
    "df_filtered = df_large.loc[mask].copy()\n",
    "\n",
    "print(f\"Lignes trouvÃ©es : {len(df_filtered)}\")\n",
    "\n",
    "# 3. Initialisation du moteur Loughran-McDonald\n",
    "lm = ps.LM()  # Charge le dictionnaire Finance\n",
    "\n",
    "def get_lm_score(text):\n",
    "    # LM a besoin de tokens (mots sÃ©parÃ©s), pas de phrases brutes\n",
    "    tokens = lm.tokenize(str(text))\n",
    "    score = lm.get_score(tokens)\n",
    "    # Le score retournÃ© est un dictionnaire : {'Positive': x, 'Negative': y, 'Polarity': z, ...}\n",
    "    # Polarity = (Pos - Neg) / (Pos + Neg). \n",
    "    return score['Polarity']\n",
    "\n",
    "# 4. Calcul (Si donnÃ©es prÃ©sentes)\n",
    "if len(df_filtered) > 0:\n",
    "    tqdm.pandas()\n",
    "    print(\"Calcul du sentiment Loughran-McDonald (Finance Specific)...\")\n",
    "    \n",
    "    # Attention : C'est un peu plus lent que VADER car la tokenisation est plus stricte\n",
    "    df_filtered['sentiment_score'] = df_filtered[col_text].progress_apply(get_lm_score)\n",
    "    \n",
    "    # 5. AgrÃ©gation\n",
    "    df_filtered['date_only'] = df_filtered[col_date].dt.date\n",
    "    daily_agg = df_filtered.groupby('date_only')['sentiment_score'].agg(['mean', 'count']).reset_index()\n",
    "    \n",
    "    # 6. Sauvegarde\n",
    "    daily_agg.to_csv('../data/daily_sentiment_lm_final.csv', index=False)\n",
    "    print(\"Fichier daily_sentiment_lm_final.csv gÃ©nÃ©rÃ© !\")\n",
    "    \n",
    "else:\n",
    "    print(\"Aucune donnÃ©e trouvÃ©e aprÃ¨s filtrage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7cacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plage de test : 2007-01-03 au 2008-12-31\n",
      "Nombre de points : 504\n",
      "--------------------------------------------------\n",
      "Test ADF pour VolatilitÃ©   : p-value = 0.3865 -> âŒ NON STATIONNAIRE (Tendance dÃ©tectÃ©e)\n",
      "Test ADF pour Sentiment    : p-value = 0.0000 -> âœ… STATIONNAIRE\n",
      "\n",
      "[ACTION] DonnÃ©es non stationnaires. Calcul des variations (Delta) J - (J-1)...\n",
      "--------------------------------------------------\n",
      "LANCEMENT DU TEST DE GRANGER (Max Lag = 15 jours)\n",
      "HypothÃ¨se : Le Sentiment 'cause' la VolatilitÃ©.\n",
      "\n",
      "LAG (Jours)  | P-VALUE    | CONCLUSION\n",
      "---------------------------------------------\n",
      "1            | 0.0203     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "2            | 0.0834     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "3            | 0.0660     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "4            | 0.0275     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "5            | 0.0388     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "6            | 0.0508     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "7            | 0.0555     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "8            | 0.0804     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "9            | 0.0754     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "10           | 0.0713     | ðŸŸ¡ TENDANCE (Faiblement significatif)\n",
      "11           | 0.0033     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "12           | 0.0025     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "13           | 0.0047     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "14           | 0.0042     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "15           | 0.0034     | ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\n",
      "\n",
      "ðŸš€ CONCLUSION : Il y a de l'Alpha ! Le sentiment prÃ©cÃ¨de la volatilitÃ© Ã  certains horizons.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sojoy/Desktop/NLP-Financial-Crisis-Modeling/quant_nlp_env/lib/python3.9/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/Users/sojoy/Desktop/NLP-Financial-Crisis-Modeling/quant_nlp_env/lib/python3.9/site-packages/numpy/linalg/_linalg.py:3220: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return _core_matmul(x1, x2)\n",
      "/Users/sojoy/Desktop/NLP-Financial-Crisis-Modeling/quant_nlp_env/lib/python3.9/site-packages/numpy/linalg/_linalg.py:3220: RuntimeWarning: overflow encountered in matmul\n",
      "  return _core_matmul(x1, x2)\n",
      "/Users/sojoy/Desktop/NLP-Financial-Crisis-Modeling/quant_nlp_env/lib/python3.9/site-packages/numpy/linalg/_linalg.py:3220: RuntimeWarning: invalid value encountered in matmul\n",
      "  return _core_matmul(x1, x2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import grangercausalitytests, adfuller\n",
    "\n",
    "# --- 1. PRÃ‰PARATION (Ton code) ---\n",
    "df_sent = pd.read_csv('../data/daily_sentiment_lm_final.csv')\n",
    "df_fine = pd.read_csv('../data/financial_data_XLF.csv')\n",
    "\n",
    "# Conversion dates\n",
    "df_sent['date_only'] = pd.to_datetime(df_sent['date_only'])\n",
    "df_fine['Date'] = pd.to_datetime(df_fine['Date']).dt.tz_localize(None)\n",
    "\n",
    "# Fusion (Inner Join)\n",
    "df_combined = pd.merge(df_fine, df_sent, left_on='Date', right_on='date_only', how='inner')\n",
    "\n",
    "# --- 2. SÃ‰LECTION DES VARIABLES ---\n",
    "# On se concentre sur les colonnes utiles et on met la date en Index (requis pour les Time Series)\n",
    "# Target (Y) = 'Volatility'\n",
    "# Predictor (X) = 'mean' (Le score sentiment brut)\n",
    "data = df_combined[['Date', 'Volatility', 'mean']].set_index('Date').sort_index()\n",
    "data = data.rename(columns={'mean': 'Sentiment'}) # Renommage pour clartÃ©\n",
    "data = data.dropna() # SÃ©curitÃ©\n",
    "\n",
    "print(f\"Plage de test : {data.index.min().date()} au {data.index.max().date()}\")\n",
    "print(f\"Nombre de points : {len(data)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 3. CHECK STATIONNARITÃ‰ (Arbitre ADF) ---\n",
    "def check_stationarity(series, name):\n",
    "    result = adfuller(series)\n",
    "    p_value = result[1]\n",
    "    is_stationary = p_value < 0.05\n",
    "    status = \"âœ… STATIONNAIRE\" if is_stationary else \"âŒ NON STATIONNAIRE (Tendance dÃ©tectÃ©e)\"\n",
    "    print(f\"Test ADF pour {name.ljust(12)} : p-value = {p_value:.4f} -> {status}\")\n",
    "    return is_stationary\n",
    "\n",
    "stat_vol = check_stationarity(data['Volatility'], \"VolatilitÃ©\")\n",
    "stat_sent = check_stationarity(data['Sentiment'], \"Sentiment\")\n",
    "\n",
    "# --- 4. TRANSFORMATION (DiffÃ©renciation si nÃ©cessaire) ---\n",
    "# Si l'un des deux n'est pas stationnaire, on diffÃ©rencie TOUT pour comparer des pommes avec des pommes.\n",
    "if not stat_vol or not stat_sent:\n",
    "    print(\"\\n[ACTION] DonnÃ©es non stationnaires. Calcul des variations (Delta) J - (J-1)...\")\n",
    "    data_test = data.diff().dropna()\n",
    "else:\n",
    "    print(\"\\n[ACTION] DonnÃ©es dÃ©jÃ  stationnaires. Utilisation des niveaux bruts.\")\n",
    "    data_test = data\n",
    "\n",
    "# --- 5. TEST DE GRANGER ---\n",
    "# Question : Est-ce que le Sentiment aide Ã  prÃ©dire la VolatilitÃ© ?\n",
    "# Ordre des colonnes CRUCIAL dans statsmodels : [Target, Predictor] -> [Volatility, Sentiment]\n",
    "\n",
    "MAX_LAG = 15  # On teste jusqu'Ã  15 jours de dÃ©calage\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"LANCEMENT DU TEST DE GRANGER (Max Lag = {MAX_LAG} jours)\")\n",
    "print(\"HypothÃ¨se : Le Sentiment 'cause' la VolatilitÃ©.\\n\")\n",
    "\n",
    "# Le verbose=True affiche tous les dÃ©tails statistiques. \n",
    "# On va le laisser Ã  False et printer juste ce qui nous intÃ©resse.\n",
    "gc_res = grangercausalitytests(data_test[['Volatility', 'Sentiment']], maxlag=MAX_LAG, verbose=False)\n",
    "\n",
    "print(f\"{'LAG (Jours)':<12} | {'P-VALUE':<10} | {'CONCLUSION'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "found_causality = False\n",
    "for lag in range(1, MAX_LAG + 1):\n",
    "    # On utilise le test Chi2 (robuste)\n",
    "    p_value = gc_res[lag][0]['ssr_chi2test'][1]\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        verdict = \"ðŸŸ¢ SIGNAL PRÃ‰DICTIF (Significatif)\"\n",
    "        found_causality = True\n",
    "    elif p_value < 0.10:\n",
    "        verdict = \"ðŸŸ¡ TENDANCE (Faiblement significatif)\"\n",
    "    else:\n",
    "        verdict = \"ðŸ”´ BRUIT (Pas de lien)\"\n",
    "        \n",
    "    print(f\"{lag:<12} | {p_value:.4f}     | {verdict}\")\n",
    "\n",
    "if found_causality:\n",
    "    print(\"\\nðŸš€ CONCLUSION : Il y a de l'Alpha ! Le sentiment prÃ©cÃ¨de la volatilitÃ© Ã  certains horizons.\")\n",
    "else:\n",
    "    print(\"\\nðŸ“‰ CONCLUSION : Pas de causalitÃ© statistique Ã©vidente sur cette pÃ©riode/mÃ©thode.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
